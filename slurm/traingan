#!/usr/bin/env bash
#SBATCH -J train-gan
#SBATCH --constraint="v100|p100"
#SBATCH --array=18-19
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=8
#SBATCH --exclusive
#SBATCH --time=22:00:00
#SBATCH --output=slurm/stdout/traingan-%A-%a.out
#SBATCH --mail-type=END
#SBATCH --mail-user=nathan.trouvain@inria.fr

task=$((SLURM_ARRAY_TASK_ID))

echo "=====Job information ====="
echo "Node List: " $SLURM_NODELIST
echo "Job ID: " $SLURM_JOB_ID
echo "Task ID: " $SLURM_ARRAY_TASK_ID
echo "Partition: " $SLURM_JOB_PARTITION
echo "Submit dir:" $SLURM_SUBMIT_DIR
echo "Submit host: " $SLURM_SUBMIT_HOST
echo "Directory: " $PWD
echo "User: " $USER

echo "Loading modules"
module load compiler/cuda/11.7
module load language/python/3.9.6

echo "==========CUDA info==========="
echo "CUDA info (from nvcc output)"
nvcc --version

echo "=========Python setup========="
echo "python : $(python3 --version), $(which python3)"
echo "pip    : $(pip3 --version), $(which pip3)"

echo "venv activation"
source ./venv/bin/activate

echo "(venv) python : $(python3 --version), $(which python3)"
echo "(venv) pip    : $(pip3 --version), $(which pip3)"

echo "======PyTorch GPU status======"
for i in `seq 1 $SLURM_JOB_NUM_NODES`; do
    srun -N1 -n1 python3 ./slurm/probegpu.py &
done
wait

echo "======Training CanaryGAN======"
srun python3 train_gan.py \
    --save_dir /beegfs/ntrouvai/canarygan/ \
    --data_dir /beegfs/ntrouvai/canarygan/dataset \
    --max_epochs 1000 \
    --batch_size 128 \
    -G "$SLURM_NTASKS_PER_NODE" \
    -c "$SLURM_CPUS_PER_TASK" \
    -N "$SLURM_JOB_NUM_NODES" \
    --seed $task \
    --version $task \
    --log_every_n_step 1 \
    --save_every_n_epochs 15 \

echo "Done !"
