#!/usr/bin/env bash
#SBATCH -J inverse
#SBATCH --constraint="a100|v100|p100"
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=12
#SBATCH --array=0-20:2
#SBATCH --time=24:00:00
#SBATCH --output=slurm/stdout/inverse-%A-%a.out
#SBATCH --mail-type=END
#SBATCH --mail-user=nathan.trouvain@inria.fr

set -e

echo "Loading modules"
module load compiler/cuda/11.7
module load language/python/3.9.6

echo "==========CUDA info==========="
echo "CUDA info (from nvcc output)"
nvcc --version

echo "=========Python setup========="
echo "python : $(python3 --version), $(which python3)"
echo "pip    : $(pip3 --version), $(which pip3)"

echo "venv activation"
source ./venv/bin/activate

echo "(venv) python : $(python3 --version), $(which python3)"
echo "(venv) pip    : $(pip3 --version), $(which pip3)"

echo "======PyTorch GPU status======"
for i in `seq 1 $SLURM_JOB_NUM_NODES`; do
    srun -N1 -n1 python3 ./slurm/probegpu.py &
done
wait

t=$((SLURM_ARRAY_TASK_ID))
EPOCH=989
DEC=9

BASE_DIR="/beegfs/ntrouvai/canarygan"


for i in `seq 0 1`; do
  g=$(find $BASE_DIR/checkpoints/version_$(($t+$i))/all/ -name "*epoch_$EPOCH-*") && \
  srun -n1 -c12 --exclusive python train_inverse.py $g \
      "$BASE_DIR/decoder/results/checkpoints/decoder-$DEC.pkl" \
      -o "$BASE_DIR/inverse_hebb3f" \
      --vec_file "$BASE_DIR/latent_vects/latent_z-dim_3.npy" \
      --learning_set "$BASE_DIR/inverse_learning_set" \
      --max_steps 12000 \
      --n_instances 10 \
      --kind "plateau" \
      --margin 0.1 \
      --tau 5 \
      --device "cuda" \
      --device_idx $i \
      &
done
wait

echo "Done !"
