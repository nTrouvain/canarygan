#!/usr/bin/env bash
#SBATCH -J probe-gpu
#SBATCH --constraint="a100|v100|p100|quadro"
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=8
#SBATCH --exclusive
#SBATCH --time=01:00:00
#SBATCH --output=slurm/stdout/%j-%A-%a.out

echo "=====probegpu information ===="
echo "Node List: " $SLURM_NODELIST
echo "Job ID: " $SLURM_JOB_ID
echo "Partition: " $SLURM_JOB_PARTITION
echo "Submit directory:" $SLURM_SUBMIT_DIR
echo "Submit host: " $SLURM_SUBMIT_HOST
echo "In the directory: " $PWD
echo "As the user: " $USER

echo "Loading modules"
module load compiler/cuda/11.7
module load language/python/3.9.6

echo "==========CUDA info==========="
echo "CUDA info (from nvcc output)"
nvcc --version

echo "=========Python setup========="
echo "python : $(python3 --version), $(which python3)"
echo "pip    : $(pip3 --version), $(which pip3)"

echo "venv activation"
source ./venv/bin/activate

echo "(venv) python : $(python3 --version), $(which python3)"
echo "(venv) pip    : $(pip3 --version), $(which pip3)"

echo "======PyTorch GPU status======"
srun python3 ./slurm/probegpu.py

echo "========Lightning test========"
srun python3 -m pmseq.tests -N "$SLURM_JOB_NUM_NODES" -G "$SLURM_NTASKS_PER_NODE" -c "$SLURM_CPUS_PER_TASK" --epochs 20 --batchsize 64 --log_freq 10

echo "Done !"
